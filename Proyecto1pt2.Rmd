---
title: "Proyecto1"
author: "Gerardo Pineda 22880, Daniel Rayo 22933"
date: "2025-02-10"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE, message=FALSE,warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
Sys.setlocale("LC_ALL", "es_ES.UTF-8")

library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(knitr)
library(dplyr)
library(psych)
library(FactoMineR)
library(fpc)
library(dplyr)
library(factoextra)
library(corrplot)
library(PCAmixdata)
library(paran)
library(tidyr)

#movies <- read.csv("./movies.csv", fileEncoding = "UTF-8", stringsAsFactors = FALSE)
movies <- read.csv("./movies.csv")
```

# Clustering
## Procesamiento del dataset

Para este apartado se decidio calcular los grupos en base a todas las variables numericas, quitando todas las variables no son de este tipo. Para posteriormente poder clasificar o ver la forma en la que se relacionan las variables por medio de estas que fueron descartadas en un inicio.

Las variables con las que se trabajara los clusters son:  
* *popularity*: Importante para agrupar películas por impacto mediático.
* *Budget*: Ayuda a diferenciar producciones de alto y bajo costo.
* *Revenue*: Relacionado con el éxito comercial.
* *runtime*: Útil para agrupar películas cortas vs. largas.
* *genresAmount*: Más géneros pueden significar una audiencia más diversa.
* *voteCount*: Relacionado con la cantidad de personas que la vieron.
* *voteAvg*: Permite separar películas mejor o peor valoradas.
* *castMenAmount y castWomenAmount*: Para analizar el tamaño del reparto y su diversidad.

```{r data without string, echo=FALSE, message=FALSE}


movies$actorsPopularityMean <- sapply(movies$actorsPopularity, function(x) {
  values <- as.numeric(unlist(strsplit(x, "\\|")))
  mean(values, na.rm = TRUE)
})

movies$castMenAmount <- as.numeric(movies$castMenAmount)

movies$castWomenAmount <- as.numeric(movies$castWomenAmount)


datos <- movies[,c("popularity", "budget", "revenue", "runtime", "genresAmount", "voteCount", "voteAvg", "castMenAmount", "castWomenAmount")]


datos <- scale(datos)
datos <- na.omit(datos)


set.seed(123)
vhopkins <- hopkins(datos)
```

Primero necesitaremos verificar si vale la pena agrupar los datos. Usando el estadistico de hopkings nos dio un resultado de `r vhopkins`, lo que indica que los resultados no son aleatorios y hay una alta posibilidad de que sea factible el agrupamiento.

Posteriormente se realizo un mapa de calor parar verificar si realmente existen patrones.  

```{r VAT, echo=FALSE, warning=FALSE, message=FALSE}
datos_dist<- dist(datos[1:1000,])
fviz_dist(datos_dist, show_labels = F)
```
  
El mapa de calor revela que existen patrones claros en los datos, con al menos tres grupos de observaciones con similitudes internas. Esto refuerza la idea de que el dataset puede dividirse en tres clusters. La presencia de áreas con colores más intensos sugiere que algunas observaciones son más similares entre sí en ciertas características, mientras que otras tienen mayor variabilidad. El dataSet puede ser bueno para representar diferentes tipos de películas en términos de su presupuesto, popularidad y desempeño en taquilla.


```{r codo}
wss=0
for (i in 1:10) 
  wss[i] <- sum(kmeans(datos[1:1000,], centers=i)$withinss)

plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
```

El método del codo sugiere que un número óptimo de clusters es k = 3, ya que en este punto la reducción en la varianza dentro de los clusters deja de ser significativa.

```{r k medias}
fviz_nbclust(datos[1:1000,], kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
```

## K means
Antes de empezar con el k mean comprobamos cual k era el mas adecuado para este clustering  

### k = 3

```{r k-means, echo=FALSE}
km <- kmeans(datos, centers = 3, iter.max = 100)


if (!is.data.frame(datos)) {
  datos <- as.data.frame(datos)
}

datos$grupoKm <- as.factor(km$cluster)

dataWithoutGroups <- subset(datos, select = -grupoKm)
```
```{r plot cluster groups, echo=FALSE}
plotcluster(dataWithoutGroups,km$cluster)
```


```{r plot cluster groups 2, echo=FALSE}
fviz_cluster(km, data = dataWithoutGroups,geom = "point", ellipse.type = "norm")
```

```{r silueta k mean, echo=FALSE}
silkm<-silhouette(km$cluster,dist(dataWithoutGroups))
plot(silkm, cex.names=.4, col=1:3)
```

### K = 2
```{r k-means2, echo=FALSE}
km <- kmeans(datos, centers = 2, iter.max = 100)

if (!is.data.frame(datos)) {
  datos <- as.data.frame(datos)
}

datos$grupoKm <- as.factor(km$cluster)

dataWithoutGroups <- subset(datos, select = -grupoKm)
```
```{r plot cluster groups2, echo=FALSE}
plotcluster(dataWithoutGroups,km$cluster)
```

```{r silueta k mean2, echo=FALSE}
silkm<-silhouette(km$cluster,dist(dataWithoutGroups))
plot(silkm, cex.names=.4, col=1:3)
```
  
Aunque el método del codo sugirió que k=3 podría ser un punto adecuado, al calcular el índice de silueta encontramos que para k=2 el valor es 0.55, significativamente mayor que el 0.18 obtenido con k=3. Esto indica que los clusters son más compactos y están mejor separados cuando se utilizan dos grupos en lugar de tres. Por esta razón, elegimos k=2, ya que proporciona una segmentación más clara y efectiva de los datos.  


## Cluster Jerarquico

```{r cluset jerarquico, echo=FALSE}

matriz_dist<- dist(dataWithoutGroups)
datos_dist<- dist(dataWithoutGroups)
hc<-hclust(datos_dist, method = "ward.D2")
plot(hc, cex=0.5, axes=FALSE)
rect.hclust(hc,k=3)
```


Aunque con k=2 la silueta fue mejor en K-means, al analizar el dendrograma del clustering jerárquico, se observó que una división natural ocurre en tres grupos. Esto sugiere que, en lugar de forzar una separación en dos clusters, el modelo jerárquico es capaz de detectar subestructuras en los datos que K-means no capturó.

```{r}
groups <- cutree(hc, k=3)
datos$gruposHC <- groups
```

```{r grafica, echo=FALSE}
plot(silhc, cex.names=.4, col=1:3)

```


## Interpretacion de los clusterings

*Comparación de resultados:*
```{r comparacion}
tabla_resultados <- data.frame(
  Algoritmo = c("K-means", "Jerárquico"),
  `Número de clusters` = c(2, 3),
  `Índice de silueta` = c(0.55, 0.51),
  Desciprció = c(
    "Mayor cohesión y separación clara",
    "El dendrograma sugiere 3 subgrupos bien diferenciados"
  )
)

kable(tabla_resultados)
```

Resumen de las variables con el metodo de k means
```{r summary de los datos, echo=FALSE, warning=FALSE}

movies <- movies[rownames(movies) %in% rownames(datos), ]

movies$grupoKm <- datos$grupoKm  
movies$grupoHC <- datos$gruposHC 


# Resumen estadístico por grupo
movies <- as.data.frame(movies)
movies_clean <- movies %>% dplyr::select(-grupoHC)

summary_by_group <- movies_clean %>%
  group_by(grupoKm) %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd), .names = "{.col}_{.fn}"), na.rm = TRUE)


variables_importantes <- c("popularity_mean", "budget_mean", "revenue_mean", "runtime_mean")

kable(summary_by_group %>% dplyr::select(all_of(variables_importantes)))

```

Resumen de las variables con el metodo de cluster jerarquico
```{r summary de los datos jerarquicos, echo=FALSE, warning=FALSE}
summary_by_groupHC <- movies %>%
  group_by(grupoHC) %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd), .names = "{.col}_{.fn}"))


variables_importantes <- c("popularity_mean", "budget_mean", "revenue_mean", "runtime_mean")

kable(summary_by_groupHC %>% dplyr::select(all_of(variables_importantes)))
```


Dado que cada algoritmo mostró un mejor desempeño con un número distinto de clusters, analizamos cómo se comportan los grupos generados en términos de las variables clave.

En general, los resultados de ambos métodos presentan distribuciones similares en algunas variables. Sin embargo, se observan diferencias significativas en presupuesto (budget) e ingresos (revenue). En el caso de k-means (k=2), los grupos reflejan una clara segmentación entre películas de mayor y menor presupuesto, con una diferencia notable en los ingresos generados.

Por otro lado, el clustering jerárquico (k=3) permite una segmentación más detallada, diferenciando un tercer grupo con películas de menor presupuesto y menor recaudación. Esta estructura ayuda a capturar mejor la diversidad de los datos, distribuyendo de manera más homogénea las películas en función de sus recursos financiero.

Comparando un poco mas los dos metodos:

En cuanto al presupuesto e ingresos, el método jerárquico logra una mejor diferenciación, incorporando un grupo adicional de películas con un presupuesto bajo (7.3M) y una recaudación igualmente baja (17.9M), lo que no ocurre en k-means, donde la segmentación es más binaria.

Ademas, la Duración de la película no parece tener diferencias significativas entre métodos, con un promedio cercano a los 100-110 minutos en la mayoría de los grupos.

Tambien, en cuanto a la popularidad no se encuentran diferencias significativas.

## eleccion de un metodo

A pesar de que K-means con k=2 obtuvo un índice de silueta superior (0.55 frente a 0.51 del clustering jerárquico con k=3), se optó por utilizar el clustering jerárquico debido a su capacidad para capturar mayor variabilidad en los datos. El clustering jerárquico con k=3 permitió una clasificación más detallada, identificando un grupo intermedio que representa películas de presupuesto medio. Esta segmentación más rica facilita un análisis más preciso de las tendencias dentro de la industria cinematográfica, asegurando que las diferencias dentro de los datos sean mejor representadas. Por lo tanto, se eligió el clustering jerárquico para el análisis de tendencias centrales y frecuencias, ya que proporciona una interpretación más equilibrada sin perder información valiosa.

```{r prespuesto vs revenues, echo=FALSE, warning=FALSE, error=FALSE}
ggplot(movies, aes(x = budget, y = revenue, color = as.factor(grupoHC))) +
  geom_point(alpha = 0.6) +
  labs(title = "Relación entre Presupuesto e Ingresos por grupo", x = "Presupuesto", y = "Ingresos") +
  theme_minimal()
```

En la grafica se puede observar las películas en función de su presupuesto e ingresos. El grupo 1 tiene la mayor diversidad, mientras que los grupos 2 y 3 presentan características más específicas en términos de inversión y rentabilidad. Esta segmentación es útil para entender la relación entre el presupuesto y el éxito financiero.


```{r actor popularidad, echo=FALSE, warning=FALSE, error=FALSE}

movies$actorsPopularityMean <- sapply(movies$actorsPopularity, function(x) {
  values <- as.numeric(unlist(strsplit(x, "\\|"))) 
  mean(values, na.rm = TRUE)
})

ggplot(movies, aes(x = as.factor(grupoHC), y = actorsPopularityMean, fill = as.factor(grupoHC))) +
  geom_boxplot() +
  labs(title = "Popularidad Promedio del Elenco por Cluster", x = "Cluster", y = "Media de Popularidad Actores") +
  theme_minimal()

```

Dado que la variable popularidad promedio del elenco no fue incluida en la formación de los clusters, es esperable que no haya una diferenciación clara entre los grupos con respecto a esta variable. Esto sugiere que la popularidad del elenco no estuvo directamente relacionada con los criterios de agrupamiento utilizados en el modelo.

```{r something}
genre_distribution <- movies_genres %>%
  group_by(grupoHC, genres) %>%
  summarise(count = n(), .groups = "drop") %>%
  pivot_wider(names_from = grupoHC, values_from = count, values_fill = 0)

colnames(genre_distribution) <- c("Generos", "Grupo 1", "Grupo 2", "Grupo 3")
kable(genre_distribution)

```

A partir de esta tabla podemos obtener que el Grupo 1 contiene la mayor diversidad y volumen de películas, lo que sugiere que es el cluster que abarca las producciones más comerciales y ampliamente distribuidas. El Grupo 2 es intermedio, con una presencia menor en todos los géneros, posiblemente representando películas con menor presupuesto o enfoque más específico.El Grupo 3 es el más reducido y especializado, con películas menos comerciales y potencialmente más orientadas a audiencias específicas, como documentales, cine independiente.

```{r distribution director}
#grupoHC
movies$director <- iconv(movies$director, from = "latin1", to = "UTF-8", sub = "")

moviesDirectors <- movies %>%
  filter(director != "" & !is.na(director))

# Separar los directores y contar ocurrencias por grupo
director_distribution <- moviesDirectors %>%
  separate_rows(director, sep = "\\|") %>%
  group_by(grupoHC, director) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(grupoHC, desc(count)) %>%
  group_by(grupoHC) %>%
  slice_max(order_by = count, n = 3)

# Mostrar en formato tabla
colnames(director_distribution) <- c("Grupo", "Director", "Conteo")
kable(director_distribution)
```

Se puede observar que en lso distintos grupos se presentan las siguientes caracteristicas: Cluster 1 agrupa a directores con una gran cantidad de películas, lo que podría significar que son responsables de sagas largas o producciones constantes. Cluster 2 contiene directores con menor volumen de películas pero con gran impacto cinematográfico.Cluster 3 tiene directores menos recurrentes en la base de datos, lo que sugiere películas más variadas en dirección.


```{r calificaciones, echo=FALSE, warning=FALSE}
avgRating <- movies %>%
  group_by(grupoHC) %>%
  summarise(avg_rating = mean(voteAvg, na.rm = TRUE)) %>%
  arrange(desc(avg_rating))

colnames(avgRating) <- c("Grupo", "Calificacion Promedio")

kable(avgRating)
```

Si bien la diferencia no es tan notable, cuando se habla de calificaciones, esta minima diferencia puede indicar factores. Se puede observar que las películas en el Grupo 2 pueden tener características que favorecen una mejor recepción por parte del público, como mayor presupuesto, actores reconocidos o mejor producción. Por otro lado, el Grupo 1, al tener la calificación más baja, podría estar compuesto por películas con menor impacto crítico.

## Conclusiones

Basado en esta informacion se pudo detectar puntos clave: 

* Grupo 1: son peliculas de bajo presupuesto con un alto rendimiento
  - Estas tienen un bajo presupuesto pero presentan un gran ingreso
  - Los generos predominantes son: Horror, Thriller, Drama (películas de bajo costo suelen ser rentables en estos géneros).
  - Directores menos conocidos.
  - Como se pudo observar en las calificaciones fue el menor impacto, porque estas peliculas no apuntan del todo a ser las mejores calificadas.
  - Si se quisiera hacer inversiones este grupo seria el mejor por su bajo presupuesto y gran recaudacion.
* Grupo 2: Blockbusters con Altos Presupuestos y Grandes Ingresos
 - Estas peliculas tienen alto presupuesto y gran ingreso
 - Géneros predominantes: Acción, Aventura, Ciencia Ficción.
 - Directores reconocidos: Spielberg, Zemeckis, Tim Burton.
 - Teniendo las peliculas mejores calificaciones.
 - Al ser Blockbusters aqui se podrian maximizar ingresos para tener franquicias o secuelas. Pero con riego financiero porque tienen un alto presupuesto y si fracasan seria una gran perdida.
* Grupo 3: Producciones de Bajo Presupuesto y Bajo Rendimiento
 - Bajo presupuesto y bajo ingreso.
 - Géneros variados y películas independientes.
 - Este grupo de peliculas al ser menor pueden beneficiarse de modelos de distribución en streaming o festivales.

--- 

# Analisis por Componentes principales

Para ello primero se requirio de la limpieza del dataset para contar solamente contar con un dataframe de variables cuantitativas. Este sería un ejemplo del Dataset con el que se trabajará el PCA.

Para ello se tomaron solo variables que eran inherentemente cuantitativas, ya que a pesar que las variables cualitativas aunque no se conviertan a un equivalente númerico, no tienen noción de orden y magnitud, y por en no aportando mucho valor al cálculo de componentes.

```{r}
PCA_raw_data_na <- na.omit(movies[,c("popularity", "budget", "revenue", "runtime", "genresAmount", "voteCount", "voteAvg", "castMenAmount", "castWomenAmount")])
PCA_raw_data_na$castMenAmount <- as.numeric(PCA_raw_data_na$castMenAmount)
PCA_raw_data_na$castWomenAmount <- as.numeric(PCA_raw_data_na$castWomenAmount)
PCA_raw_data <- PCA_raw_data_na[complete.cases(PCA_raw_data_na), ]
kable(head(PCA_raw_data))
```

## PCA es aplicable
Acto seguido, es importantes verificar si el PCA será una buena técnica para este conjunto de datos. Empezando por revisar la colinealidad de las variables: 

```{r}
rcor<-cor(PCA_raw_data, use = "pairwise.complete.obs")
corrplot(rcor)
```
Vemos un valor es `r det(rcor)`, que es cercano a 0, y también podemos ver que hay una relación del estrecha (cercana al 60%) entre las ganancias y el presupuesto, así como número de votos y ganancias. Para reafirmar si el PCA será un método correcto, se corrieron tambien los test KMO y Test de esfericidad de Bartlet que arrojan los siguientes indicios:

**KMO**
```{r}
KMO(as.matrix(PCA_raw_data))
```
**Esfericidad de Bartlet**
```{r}
cortest.bartlett(PCA_raw_data)
```
Ambas estadísticas ofrecen resultados favorecedores al indica que si hay relación entre las diferentes variables y datos con con un MSA superior a 0.5 (MSA=0.71) y bartlet indicando que si hay interdependencia entre las variables (p=0). Es decir, podemos procer a aplicar PCA.


## Aplicación de PCA

Estas serian las componentes de principales del subset de datos.
```{r}
sum(is.na(PCA_raw_data))
compPrinc<-prcomp(PCA_raw_data, scale = T)
compPrinc
```
Por la regla de Kaiser (las componentes con desviacion estandar mayor a 1 son las que aportan mayor peso) se desvela que las primeras 77% componentes son las más importantes al explicar el 86% de la variación de los datos:

```{r}
summary(compPrinc)
```
La gŕafica recomienda el uso de 2 componentes, pero para encontrar, eso explicaria solo el 44% de la variabilidad de los datos, así que nos quedaremos en el análisis con componentes: 
```{r screeplot}
fviz_eig(compPrinc, addlabels = TRUE, ylim = c(0, 80))
fviz_eig(compPrinc, addlabels = TRUE, choice = c("eigenvalue"), ylim = c(0, 3))
```
## Interpretación de PSA

El siguiente gráfico muestra vectores proyectos sobre las 2 primeras componentes. Y se puede observar las relaciones descubiertas en pasos anteriorres sobre la covarianza: Las componetnes de presupuesto, y número de votos y ganancias estan muy relacionadas positivamente entre, y bien representadas en la primera dimensión.

También se puede decir algo parecido del tiempo de expiración y el promedio de votos, solo que estos 2 ultimos se encuentran menos representados en la 1 y 2 dimensión.
```{r grafico coseno}
fviz_pca_var(compPrinc, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
)

```
